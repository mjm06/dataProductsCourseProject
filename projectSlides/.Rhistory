type="n"))
with(subset(new.merge, DensityIndex==i), points(log10(ExpValue), log10(ExpDensity), col="#3399FF4C",pch=19))  #blue
with(subset(new.merge, DensityIndex==i+1), points(log10(ExpValue), log10(ExpDensity), col="#FF99334C",pch=19))  #orange
name.cutoff<-paste("cutoff b/w ZipIndex",i,"to",i+1)
sampleData<-all.merge #create a new version of all.merge to play with.
head(sampleData)
str(sampleData)
plot(DensityIndex~(log10(ExpDensity)), data=sampleData, col="blue", pch=19)
sampleData$DensityIndex<-as.factor(sampleData$DensityIndex)
require(ggplot2)
qplot(data = sampleData,
x = log10(ExpDensity),
y = DensityIndex,
color = DensityIndex,
size  = log10(ExpValue),
alpha = I(0.7))
qplot(data = sampleData,
x = log10(ExpValue),
y = log10(ExpDensity),
color = DensityIndex,
size = 8,
alpha = I(0.4))
head(sampleData)
sampleData$DensityIndex2<-sampleData[,10==(as.numeric(sampleData$DensityIndex)-1)
sampleData$DensityIndex2<-sampleData[,10==(as.numeric(sampleData$DensityIndex)-1)]
head(sampleData)
sampleData$DensityIndex2<-as.numeric(sampleData$DensityIndex)-1)
sampleData$DensityIndex2<-as.numeric((sampleData$DensityIndex)-1)
sampleData$DensityIndex2<-as.numeric(sampleData$DensityIndex)-1
head(sampleData)
sampleData$DensityIndex2<-sampleData[,10]
head(sampleData)
sampleData$DensityIndex2<-as.numeric(sampleData$DensityIndex)-1
head(sampleData)
sampleData<-sampleData[,c(1:9, 12, 10:11)]
head(sampleData)
fit1<-lm(DensityIndex2~(log10(ExpDensity)), data=sampleData)
fit2<-lm(DensityIndex2~(log10(ExpDensity))+NumRisks+StateName, data=sampleData)
summary(fit1)
plot(DensityIndex2~log10(ExpDensity), data=sampleData)
abline(fit1)
abline(fit2, col="blue")
summary(fit2)
fit2<-lm(DensityIndex2~(log10(ExpDensity))+NumRisks, data=sampleData)
summary(fit2)
str(sampleData)
qplot(data = sampleData,
x = log10(ExpValue),
y = log10(ExpDensity),
color = DensityIndex,
size = NumRisks,
alpha = I(0.4))
fit3<-lm(DensityIndex2~(log10(ExpDensity))+(log10(ExpValue))+NumRisks, data=sampleData)
anova(fit2,fit3)
fit3<-lm(DensityIndex2~(log10(ExpDensity))+NumRisks+(log10(ExpValue)), data=sampleData)
anova(fit2,fit3)
summary(fit2)
summary(fit3)
predict(fit3, newdata=data.frame(DensityIndex2=0), interval="prediction", level=0.95)
predict(fit3, newdata=data.frame(DensityIndex2=0, ExpDensity=mean(sampleData$ExpDensity)), interval="prediction", level=0.95)
predict(fit3, newdata=data.frame(DensityIndex2=0, ExpDensity=sampleData[sampleData$DensityIndex==0,mean(sampleData$ExpDensity)], NumRisks=mean()), interval="prediction", level=0.95)
predict(fit3, newdata=data.frame(DensityIndex2=0, ExpDensity=sampleData[sampleData$DensityIndex2==0,mean(sampleData$ExpDensity)], NumRisks=mean()), interval="prediction", level=0.95)
subData0<-sampleData[sampleData$DensityIndex2==0, ]
expDensity0<-sampleData[sampleData$DensityIndex2==0, ]
avNumRisks<-expDensity0[,expDensity0$NumRisks]
avNumRisks<-mean(expDensity0$NumRisks)
test<-expDensity0$NumRisks
head(test)
summary(test)
predict(fit3, newdata=data.frame(DensityIndex2=0, ExpDensity=expDensity0, NumRisks=avNumRisks), interval="prediction", level=0.95)
predict(fit3, newdata=data.frame(DensityIndex2=0, ExpDensity2=expDensity0, NumRisks=avNumRisks), interval="prediction", level=0.95)
predict(fit3, newdata=data.frame(DensityIndex2=0, ExpDensity2=expDensity0, ExpDensity=expDensity0, NumRisks=avNumRisks), interval="prediction", level=0.95)
fit3
summary(fit3)
predict(fit3, newdata=data.frame(DensityIndex2=0, ExpDensity2=expDensity0, ExpDensity=expDensity0, NumRisks=avNumRisks), interval="prediction", level=0.95)
predict(fit3, newdata=data.frame(ExpDensity2=expDensity0, ExpDensity=expDensity0, NumRisks=avNumRisks), interval="prediction", level=0.95)
colnames(sampleData)
predict(fit3, newdata=data.frame(log10(ExpDensity2)=expDensity0, log10(ExpDensity)=expDensity0, NumRisks=avNumRisks), interval="prediction", level=0.95)
predict(fit3, newdata=data.frame(log10(ExpDensity2)=expDensity0, log10(ExpDensity)=expDensity0, NumRisks=avNumRisks), interval="prediction", level=0.95)
predict(fit3, newdata=data.frame(log10(ExpDensity2)=expDensity0, log10(ExpDensity)=expDensity0, NumRisks=avNumRisks), interval="prediction", level=0.95)
predict(fit3, newdata=data.frame(log10(ExpDensity2)=expDensity0, log10(ExpDensity)=expDensity0, NumRisks=avNumRisks), interval=prediction, level=0.95)
expDensity0<-sampleData[sampleData$DensityIndex2==0, ]
avNumRisks<-mean(expDensity0$NumRisks)
newData<-cbind(expDensity0, expDensity0, avNumRisks)
colnames(newData)<-c("ExpDensity2", "ExpDensity", "NumRisks")
newData
head(newData)
head(sampleData)
expDensity0<-sampleData[sampleData$DensityIndex2==0, 6:8]
avNumRisks<-mean(expDensity0$NumRisks)
head(expDensity0)
expDensity0<-sampleData[sampleData$DensityIndex2==0,]
head(expDensity0)
expD<-mean(expDensity0$ExpDensity)
newData<-cbind(expD, expD, avNumRisks)
colnames(newData)<-c("ExpDensity2", "ExpDensity", "NumRisks")
head(newData)
predict(fit3, newdata=newData, interval="prediction", level=0.95)
str(newData)
newData<-data.frame(newData)
colnames(newData)<-c("ExpDensity2", "ExpDensity", "NumRisks")
predict(fit3, newdata=newData, interval="prediction", level=0.95)
expV<-mean(expDensity0$ExpValue)
expV<-mean(expDensity0$ExpValue)
newData<-cbind(expD, expV, avNumRisks)
head(newData)
predict(fit3, newdata=newData, interval="prediction", level=0.95)
newData<-data.frame(newData)
colnames(newData)<-c("ExpDensity2", "ExpValue", "NumRisks")
predict(fit3, newdata=newData, interval="prediction", level=0.95)
newData<-cbind(expD, expV, avNumRisks)
newData<-data.frame(newData)
colnames(newData)<-c("ExpDensity", "ExpValue", "NumRisks")
predict(fit3, newdata=newData, interval="prediction", level=0.95)
require(UsingR)
data(galton)
galton<-data.frame(galton)
par(mfrow=c(1,2))
hist(galton$child, col="blue", breaks=100)
hist(galton$parent, col="green", breaks=100)
require(manipulate)
myHist<-function(mu){
hist(galton$child, col="blue", breaks=100)
lines(c(mu, mu), c(0,150), col="red", lwd=5)
mse<-mean((galton$child-mu)^2)
text(63, 150, paste("mu= ", mu))
text(63, 140, paste("MSE= ", round(mse,2)))
}
manipulate(myHist(mu), mu=slider(62, 74, step=0.5))
manipulate(myHist(mu), mu=slider(62, 74, step=0.5))
manipulate(myHist(mu), mu=slider(62, 74, step=0.5))
manipulate(myHist(mu), mu=slider(62, 74, step=0.5))
plot(galton$parent, galton$child, pch=19, col="blue")
freqData <- as.data.frame(table(galton$child, galton$parent))
names(freqData) <- c("child", "parent", "freq")
freqData$child <- as.numeric(as.character(freqData$child))
freqData$parent <- as.numeric(as.character(freqData$parent))
radius<-sqrt(freqData$freq/pi)
symbols(freqData$parent, freqData$child, circle=radius, inches=0.25,
fg="white", bg="red",
main="Bubble Plot of Children's Heights Versus Parents' Heights")
text(freqData$parent, freqData$child, cex=0.5)
head(freqData)
table(galton$child, galton$parent)
as.data.frame(table(galton$child, galton$parent00))
as.data.frame(table(galton$child, galton$parent))
??table
str(galton)
myPlot<-function(beta){
y<-galton$child-mean(galton$child)
x<-galton$parent-mean(galton$parent)
freqData<-as.data.frame(table(x,y))
names(freqData)<-c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch=21, col="black", bg="lightblue",
cex=.15*freqData$freq,
xlab="parent",
ylab="child")
abline(0, beta, lwd=3)
points(0,0,cex=2, pch=19)
mse<-mean((y-beta*x)^2)
title(paste("beta= ", beta, "mse = ", round(mse, 3)))
}
manipulate(myPlot(beta), beta=slider(0.8, 1.2, step=0.2))
manipulate(myPlot(beta), beta=slider(0.8, 1.2, step=0.2))
manipulate(myPlot(beta), beta=slider(0.8, 1.2, step=0.1))
lm(I(child-mean(child))~I(parent-mean(parent))-1, data=galton)
fit<-lm(I(child-mean(child))~I(parent-mean(parent))-1, data=galton)  #the "-1" means "don't fit an intercept.
summary(fit)
lm(child~parent, data=galton)
head(sampleData)
cor(ExpValue, ExpDensity, data=sampleData)
cor(sampleData$ExpValue, sampleData$ExpDensity)
cor(sampleData$DensityIndex2, sampleData$ExpDensity)
example(anscombe)
data(mtcars)
fit.cars <- lm(mpg~wt,data=mtcars)
#Confidence and prediction intervals with the original x values:
p_conf1 <- predict(fit.cars,interval="confidence")
p_pred1 <- predict(fit.cars,interval="prediction")
#Conf. and pred. intervals with new x values (extrapolation and more finely/evenly spaced than original data):
nd <- data.frame(x=seq(0,8,length=51))
p_conf2 <- predict(fit.cars,interval="confidence",newdata=nd)
p_pred2 <- predict(fit.cars,interval="prediction",newdata=nd)
p_conf1 <- predict(fit.cars,interval="confidence")
p_pred1 <- predict(fit.cars,interval="prediction")
nd <- data.frame(x=seq(0,8,length=51))
p_conf2 <- predict(fit.cars,interval="confidence",newdata=nd)
nd <- data.frame(wt=seq(0,8,length=51))
p_conf2 <- predict(fit.cars,interval="confidence",newdata=nd)
p_pred2 <- predict(fit.cars,interval="prediction",newdata=nd)
#Plotting everything together:
plot(mpg~wt,data=mtcars) ## data
plot(mpg~wt,data=mtcars) ## data
plot(mpg~wt,data=mtcars) ## data
matlines(d$x,p_conf1[,c("lwr","upr")],col=2,lty=1,type="b",pch="+")
plot(mpg~wt,data=mtcars) ## data
plot(mpg~wt,data=mtcars) ## data
abline(fit.cars) ## fit
matlines(d$x,p_conf1[,c("lwr","upr")],col=2,lty=1,type="b",pch="+")
nd
head(p_conf1)
??matlines
head(nd)
d<-mtcars
matlines(d$x,p_conf1[,c("lwr","upr")],col=2,lty=1,type="b",pch="+")
data(diamond)
require(UsingR)
data(diamond)
head(diamond)
y<-diamond$price; x<-diamond$carat; n<-length(y)
xVals<-seq(min(x), max(x), by=.01)
fit<-lm(y~x, data=diamond)
xVals<-seq(min(x), max(x), by=.01)
newdata<-data.frame(x=xVals)
p1<-predict(fit, newdata, interval=("confidence"))
p2<-predict(fit, newdata, interval=("prediction"))
plot(x, y, frame=FALSE, xlab="Carat", ylab="Dollars", pch=21, col="black", bg="lightblue", cex=2)
abline(fit, lwd=2)
lines(xVals, p1[,2]); lines(xVals, p1[,3])
lines(xVals, p2[,2]); lines(xVals, p2[,3])
lines(xVals, p1[,2], col="red"); lines(xVals, p1[,3], col="red")  #Plots the confidence interval.
data(Heating)
require(mlogit)
data(Heating)
i<-0
##pull the UrbanDensity data (LOBComb1, 100.txt) and experiment with predicting DensityIndex
##on the basis of log10(ExpDensity).
id.cols<-read.csv("C:/Users/I50167/Desktop/100.txt", nrow=10, stringsAsFactors=FALSE)
first5rows<-read.table("C:/Users/I50167/Desktop/100.txt", skip=11, nrow=5, header=FALSE, stringsAsFactors=FALSE, quote="\"")
first5rows<-data.frame(first5rows)
colnames(first5rows)<-c("ZipCode", "StateFips", "CountyFips", "Longitude", "Latitude", "ExpValue", "ExpDensity", "NumRisks")
allStates<-read.table("C:/Users/I50167/Desktop/100.txt", skip=11, header=FALSE, stringsAsFactors=FALSE, quote="\"")
colnames(allStates)<-c("ZipCode", "StateFips", "CountyFips", "Longitude", "Latitude", "ExpValue", "ExpDensity", "NumRisks")
zip.index<-read.csv("H:/Terrorism Project/UrbanDensity/UrbanDensityExposure/ZIP Density Final.csv")
colnames(zip.index)<-c("ZipCode", "DensityIndex")
#Pull the state information (name, abbreviation, fips).
state.info<-read.csv("H:/Terrorism Project/UrbanDensity/UrbanDensityExposure/StateInfo.csv")
colnames(state.info)<-c("StateName", "StateAbb", "StateFips")
#Merge all.data to zip.index.Use ONLY the zip codes that zip.index and all.data have in common --
#ZIP codes change frequently, and since the vintage of the zip.index file is unknown, we'll
#ignore non-matching ZIPs and keep only the zips known to be in the U.S. IED in 2006 (all.data).
all.merge<-merge(allStates, zip.index,
by.x="ZipCode",
by.y="ZipCode",
all=TRUE, all.x=FALSE, all.y=FALSE)
all.merge<-merge(all.merge, state.info, by.x="StateFips",
by.y="StateFips",
all=TRUE, all.x=FALSE, all.y=FALSE)
new.merge<-all.merge
##
LOB.option<-"100"  ## this is hard-coded, but in the makePlotZipAnalysisWithOptimization script,
## it's deciphered by the script.***
#plot the logExpDensity vs. logExpValue for the two Density Indices, i and i+1.
with(new.merge, plot(log10(ExpValue), log10(ExpDensity),
main=bquote("Log10 Exposure Density vs. Log Exposure Value; LOB Option: "~.(LOB.option)),
xlab="log10 Exposure Value",
ylab="log10 Exposure Density",
type="n"))
with(subset(new.merge, DensityIndex==i), points(log10(ExpValue), log10(ExpDensity), col="#3399FF4C",pch=19))  #blue
with(subset(new.merge, DensityIndex==i+1), points(log10(ExpValue), log10(ExpDensity), col="#FF99334C",pch=19))  #orange
name.cutoff<-paste("cutoff b/w ZipIndex",i,"to",i+1)
sampleData<-all.merge #create a new version of all.merge to play with.
plot(DensityIndex~(log10(ExpDensity)), data=sampleData, col="blue", pch=19)
sampleData$DensityIndex2<-as.numeric(sampleData$DensityIndex)-1
sampleData<-sampleData[,c(1:9, 12, 10:11)]
fit1<-lm(DensityIndex2~(log10(ExpDensity)), data=sampleData)
plot(DensityIndex2~log10(ExpDensity), data=sampleData)
abline(fit1)
fit2<-lm(log10(ExpDensity)~(log10(ExpValue)), data=sampleData)
plot(log10(ExpDensity)~(log10(ExpValue)), data=sampleData)
abline(fit2)
fit1.logit<-multinom(DensityIndex~ExpDensity+ExpValue+NumRisks, data=sampleData)
require(foreign)
require(nnet)
require(ggplot2)
require(reshape2)
require(mlogit)
fit1.logit<-multinom(DensityIndex~ExpDensity+ExpValue+NumRisks, data=sampleData)
summary(fit1.logit)
fit2.logit<-multinom(DensityIndex~ExpDensity+ExpValue+NumRisks+ZipCode+ExpDensity:ExpValue+ExpDensity:ZipCode+ExpValue:ZipCode, data=sampleData)
summary(fit2.logit)
data.frame(exp(fit2.logit$coefficients))
fit2.logit<-multinom(DensityIndex~ExpDensity+ExpValue+NumRisks+ZipCode+ExpDensity:ExpValue+ExpDensity:ZipCode+ExpValue:ZipCode, data=sampleData)
fit2.logit$coefficients
summary(fit2.logit)
exp(fit2.logit$coefficients)
data.frame(exp(fit2.logit$coefficients, ignore.na=TRUE))
summary(fit2.logit)
crosstab(sampleData_)
??crosstab
xtabs(sampleData)
table(sampleData)
install.packages("gmodels")
require(gmodels)
pairs(sampleData)
CrossTable(sampleData)
require(caret)
require(kernlab)
data(spam)
inTrain<-createDataPartition(y=spam$type, p=0.75, list=FALSE)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
dim(training)
set.seed(32343)  #to ensure reproducibility later.
modelFit<-train(type ~., data=training, method="glm")
predictions<-predict(modelFit, newdata=testing)
predictions  #view our predictions
confusionMatrix(predictions, testing$type)
dim(training)
# We'll explore these techniques using the "wage" dataset in the ISLR library.
require(ISLR)
require(ggplot2)
require(gridExtra)
require(caret)
data(Wage)
summary(Wage)
inTrain<-createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training<-Wage[inTrain,]
testing<-Wage[-inTrain,]
dim(training); dim(testing)
featurePlot(x=training[, c("age", "education", "jobclass")],
y=training$wage, plot="pairs")
plot(wage~age, data=training, pch=20)
qplot(age, wage, data=training)
qplot(age,wage,colour=jobclass, data=training)
qq<-qplot(age,wage,colour=education, data=training)
qq+geom_smooth(method='lm', formula=y~x)
require(Hmisc)
cutWage<-cut2(training$wage, g=3)
table(cutWage)
#Now, We'll use the cutWage to help us make more plots.
p1<-qplot(cutWage, age, data=training, fill=cutWage,
geom=c("boxplot"))
p1
p2<-qplot(cutWage, age, data=training, fill=cutWage,
geom=c("boxplot", "jitter"))
grid.arrange(p1,p2, ncol=2)
t1<-table(cutWage, training$jobclass)
t1
prop.table(t1,1)
qplot(wage, colour=education, data=training, geom="density")
library(caret)
library(kernlab)
library(RANN)
data(spam)
set.seed(1234)
inTrain<-createDataPartition(y=spam$type, p=0.75, list=FALSE)
training<-spam[inTrain, ]
testing<-spam[-inTrain, ]
hist(training$capitalAve, main="", xlab="ave. capital run length")
mean(training$capitalAve)
sd(training$capitalAve)
trainCapAve<-training$capitalAve
trainCapAveS<-(trainCapAve-mean(trainCapAve))/sd(trainCapAve)
mean(trainCapAveS)
#Note that the mean of the standardized
#data (trainCapAveS) is close to zero.
sd(trainCapAveS)
testCapAve<-testing$capitalAve
testCapAveS<-(testCapAve-mean(testCapAve))/sd(testCapAve)
mean(testCapAveS)
sd(testCapAveS)
preObj<-preProcess(training[,-58], method=c("center","scale"))
trainCapAveS<-predict(preObj, training[,-58])$capitalAve
mean(trainCapAveS)
sd(trainCapAveS)
hist(trainCapAveS)
testCapAveS<-predict(preObj, testing[,-58])$capitalAve
mean(testCapAveS)
sd(testCapAveS)
set.seed(32343)
modelFit<-train(type ~.,data=training,
preProcess=c("center", "scale"),
method="glm")
modelFit
preObj<-preProcess(training[,-58],method=c("BoxCox"))
trainCapAveS<-predict(preObj, training[-58])$capitalAve
par(mfrow=c(1,2))
hist(trainCapAveS)
qqnorm(trainCapAveS)
data(iris); library(ggplot2)
names(iris)
table(iris$Species)
inTrain<-createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training<-iris[inTrain, ]
testing<-iris[-inTrain, ]
dim(training); dim(testing) #check the sizes of these dfs.
require(caret)
setwd("C:/Users/I50167/Desktop/Developing Data Products")
library(shiny)
library(ggplot2)
runApp()
runApp("sleepy-app")
install.packages("devtools")
library(devtools)
devtools::install_github('rstudio/shinyapps')
library(shinyapps)
install_github("slidify", "ramnathv")
install_github("slidifyLibraries", "ramnathv")
library(slidify)
library(slidifyLibraries)
shinyapps::setAccountInfo(
name="mjmarkey",
token="3B3FA0A50471473B826702B917424931",
secret="cANSA5LAqQH7D8QXMd7RV0OpMeCgeaofgp5lPTQk")
author("projectSlides")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
head(msleep)
??msleep
runApp("sleepy-app")
runApp("sleepy-app")
slidify("index.Rmd")
head(msleep)
unique(msleep$genus)
unique(msleep$ordere)
unique(msleep$order)
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
head(msleep[, c(1-4, 5, 6, 11)})])
head(msleep[, c(1-4, 5, 6, 11)])
head(msleep[, 1-4])
head(msleep[, c(1-4, 5, 6, 11)])
colnames(msleep)
colnames(msleep)
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
data(msleep)
head(msleep)
howmany<-msleep[!(msleep$vore %in% NA), ]
howmany2<-msleep[(msleep$vore %in% NA), ]
head(howmany2)
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
omni<-msleep$vore=="omni"
head(omni)
omni
omni<-msleep[msleep$vore=="omni", ]
head(omni)
unique(omni$order)
unique(carnivores$order)
unique(carnivores$order)
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
